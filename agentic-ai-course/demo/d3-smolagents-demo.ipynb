{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "introduction",
   "metadata": {},
   "source": [
    "# Smolagents Demo\n",
    "\n",
    "This notebook demonstrates **Smolagents**, HuggingFace's lightweight framework for building AI agents.\n",
    "\n",
    "## Required Environment Variables\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY    # Your OpenAI API key (required)\n",
    "```\n",
    "\n",
    "Please refer to the [README](README.md) for instructions on setting up environment variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xxwm7sfec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running standalone without the project setup:\n",
    "# pip install smolagents openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Import Smolagents components\n",
    "from smolagents import CodeAgent, OpenAIServerModel, WebSearchTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "models-concept",
   "metadata": {},
   "source": [
    "## ü§ñ Models in Smolagents\n",
    "\n",
    "Smolagents is **model-agnostic** - it works with any LLM! Let's explore the different model types but focus on OpenAI integration.\n",
    "\n",
    "### Available Model Types:\n",
    "\n",
    "1. **OpenAIServerModel** - Direct OpenAI API integration (recommended)\n",
    "2. **InferenceClientModel** - For HuggingFace Hub models\n",
    "3. **TransformersModel** - For local models via transformers\n",
    "4. **AzureOpenAIServerModel** - For Azure OpenAI\n",
    "5. **LiteLLMModel** - Universal provider interface (optional)\n",
    "\n",
    "We'll use **OpenAIServerModel** for direct, simple OpenAI integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "models-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI model directly\n",
    "model = OpenAIServerModel(\n",
    "    model_id=\"gpt-5-mini\",\n",
    "    api_key=os.getenv('OPENAI_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1n44sg4k1sj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model directly (without tools or agent)\n",
    "from smolagents.models import ChatMessage\n",
    "\n",
    "print(\"Testing model directly...\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    # Simple test prompt for code generation\n",
    "    test_prompt = \"Write a simple Python function to calculate the factorial of a number.\"\n",
    "\n",
    "    print(f\"Prompt: {test_prompt}\")\n",
    "    print(\"\\nGenerating response...\")\n",
    "\n",
    "    # Create message in correct format\n",
    "    messages = [ChatMessage(role=\"user\", content=test_prompt)]\n",
    "\n",
    "    # Call the model with message list\n",
    "    response = model(messages)\n",
    "\n",
    "    # Extract the content from response\n",
    "    response_text = response.content\n",
    "\n",
    "    print(\"‚úì Model test successful!\")\n",
    "    print(\"\\nModel Response:\")\n",
    "    print(\"-\" * 40)\n",
    "    # Show first 500 chars or full response if shorter\n",
    "    if len(response_text) > 500:\n",
    "        print(f\"{response_text[:500]}...\")\n",
    "        print(f\"\\n[Response truncated - {len(response_text)} total characters]\")\n",
    "    else:\n",
    "        print(response_text)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Model test failed: {e}\")\n",
    "    print(\"Please check your OPENAI_API_KEY environment variable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dlwe893iow",
   "metadata": {},
   "source": [
    "### Model Configuration\n",
    "\n",
    "**Current Setup:**\n",
    "- **Type:** OpenAIServerModel\n",
    "- **Model:** gpt-4o-mini\n",
    "- **Provider:** OpenAI (direct)\n",
    "- **Status:** Ready\n",
    "\n",
    "**Why this model choice?**\n",
    "- Fast inference for demos\n",
    "- Cost-effective\n",
    "- Excellent code generation\n",
    "- Strong tool-calling capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-comparison",
   "metadata": {},
   "source": [
    "### Model Integration Options\n",
    "\n",
    "#### 1. OpenAI Direct (current):\n",
    "```python\n",
    "OpenAIServerModel(model_id='gpt-4o-mini', api_key=...)\n",
    "```\n",
    "\n",
    "#### 2. HuggingFace Hub models:\n",
    "```python\n",
    "InferenceClientModel('microsoft/DialoGPT-medium')\n",
    "```\n",
    "\n",
    "#### 3. Local models:\n",
    "```python\n",
    "TransformersModel(pipeline('text-generation', model='gpt2'))\n",
    "```\n",
    "\n",
    "#### 4. Other providers (via LiteLLM):\n",
    "```python\n",
    "LiteLLMModel('claude-3-sonnet-20240229')  # Anthropic\n",
    "LiteLLMModel('gemini-pro')                # Google\n",
    "```\n",
    "\n",
    "**‚ú® Smolagents works with ANY of these models!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tools-concept",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Tools in Smolagents\n",
    "\n",
    "Tools are the key to agent capabilities. In Smolagents, tools are exposed as **Python functions** that agents can call dynamically.\n",
    "\n",
    "### Built-in Tools:\n",
    "- **WebSearchTool** - Web search functionality  \n",
    "- **PythonInterpreterTool** - Execute Python code\n",
    "- **Custom tools** - Create your own!\n",
    "\n",
    "### Tool Integration:\n",
    "- üåê **Hub Integration** - Share/pull tools from HuggingFace Hub\n",
    "- üîó **LangChain compatibility** - Use existing LangChain tools\n",
    "- üéØ **MCP support** - Model Context Protocol servers as tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tools-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and test WebSearchTool\n",
    "search_tool = WebSearchTool()\n",
    "\n",
    "print(\"WebSearchTool initialized\")\n",
    "print(f\"   Type: {type(search_tool).__name__}\")\n",
    "print(f\"   Description: {search_tool.description}\")\n",
    "\n",
    "print(\"\\nTesting tool independently:\")\n",
    "try:\n",
    "    # Test the tool directly\n",
    "    result = search_tool(\"Singapore population 2024\")\n",
    "    print(\"Search successful!\")\n",
    "    print(f\"Result preview: {result[:200]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"Tool test: {str(e)}\")\n",
    "    print(\"   (This is normal if no internet or API limits)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "codeagent-action",
   "metadata": {},
   "source": [
    "## üöÄ CodeAgent in Action: Bringing Models + Tools Together\n",
    "\n",
    "Now let's create a **CodeAgent** that combines our OpenAI model with search tools to demonstrate the power of code-based agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CodeAgent with model and tools\n",
    "agent = CodeAgent(\n",
    "    tools=[search_tool],\n",
    "    model=model,\n",
    "    max_steps=3  # Limit for safety in demo (changed from max_tool_calls)\n",
    ")\n",
    "\n",
    "print(\"CodeAgent Created!\")\n",
    "print(f\"   Model: {model.__class__.__name__} (gpt-4o-mini)\")\n",
    "print(f\"   Tools: {len(agent.tools)} available\")\n",
    "print(f\"   - {search_tool.__class__.__name__}\")\n",
    "print(\"   Max steps: 3 (for demo safety)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-query",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple query demonstrating search + reasoning\n",
    "query = \"What is the current population of Singapore? Please search for recent data.\"\n",
    "\n",
    "print(f\"User Query: {query}\")\n",
    "print(\"\\nAgent Processing...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    result = agent.run(query)\n",
    "\n",
    "    print(\"\\nAgent Response:\")\n",
    "    print(\"=\"*60)\n",
    "    print(result)\n",
    "    print(\"=\"*60)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    print(\"This might be due to API limits or network issues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-example",
   "metadata": {},
   "source": [
    "## üéØ Advanced Example: Multi-step Research and Comparison\n",
    "\n",
    "Let's demonstrate Smolagents' strength with a complex query that requires multiple search steps and data comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-query",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex multi-step query\n",
    "complex_query = \"\"\"\n",
    "I want to compare two major cities in Asia:\n",
    "1. Find the population of Singapore\n",
    "2. Find the population of Hong Kong\n",
    "3. Calculate the difference between them\n",
    "4. Tell me which one is larger and by how much (as a percentage)\n",
    "\n",
    "Please search for current data and show your calculation steps.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Complex Research Query:\")\n",
    "print(complex_query)\n",
    "print(\"\\nAgent Processing Complex Multi-step Task...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    result = agent.run(complex_query.strip())\n",
    "\n",
    "    print(\"\\nAgent Response:\")\n",
    "    print(\"=\"*70)\n",
    "    print(result)\n",
    "    print(\"=\"*70)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n",
    "    print(\"This might be due to API limits or network issues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## üìã Summary: Smolagents Key Takeaways\n",
    "\n",
    "This notebook demonstrated HuggingFace's **Smolagents** framework through hands-on examples showcasing the two core concepts:\n",
    "\n",
    "### ü§ñ **Models**\n",
    "‚úÖ **Model-agnostic design** - Works with any LLM  \n",
    "‚úÖ **OpenAI integration** - Seamless via LiteLLM  \n",
    "‚úÖ **Flexible options** - Local, Hub, API providers  \n",
    "‚úÖ **Easy configuration** - Minimal setup required  \n",
    "\n",
    "### üõ†Ô∏è **Tools**\n",
    "‚úÖ **Built-in tools** - DuckDuckGoSearchTool, WebSearchTool  \n",
    "‚úÖ **Custom tools** - Easy to create and integrate  \n",
    "‚úÖ **Python functions** - Tools as callable functions  \n",
    "‚úÖ **Hub integration** - Share and discover community tools  \n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- **GitHub**: [huggingface/smolagents](https://github.com/huggingface/smolagents)\n",
    "- **Documentation**: [HuggingFace Smolagents Docs](https://huggingface.co/docs/smolagents)\n",
    "- **Blog Post**: [Introducing smolagents](https://huggingface.co/blog/smolagents)\n",
    "- **Course**: [Building Code Agents with HuggingFace smolagents](https://www.deeplearning.ai/short-courses/building-code-agents-with-hugging-face-smolagents/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
